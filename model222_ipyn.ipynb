{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Spatial Flow Prediction: True Values, Predictions, and Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data and feature construction\n",
    "\n",
    "We start from a DuckDB database `mobility.duckdb` stored in Google Drive.  \n",
    "\n",
    "YJMob100K is an open-source, anonymized, metropolitan-scale human mobility dataset derived from mobile phone location data (Yahoo Japan / LY Corporation). To protect privacy, both space and time are discretized: locations are mapped onto a 500 m × 500 m grid and timestamps are binned into 30-minute intervals; the actual city and absolute dates are not disclosed, and records are indexed using day and time-slot identifiers instead. \n",
    "Nature\n",
    "\n",
    "In addition to mobility traces, the release provides static, cell-level context via a POI-category count vector (about 85 dimensions) for each grid cell, enabling models to combine dynamic mobility signals with local urban context. In this notebook, we operate on an aggregated table (flow_poi) that summarizes the discretized trajectories into half-hour, grid-level flows and joins them with the POI vectors, producing a spatiotemporal grid time series suitable for next-step flow prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "con = duckdb.connect(\"/content/drive/MyDrive/MOBILITY/mobility.duckdb\")\n",
    "\n",
    "con.execute(\"SHOW TABLES;\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Inspecting the base table\n",
    "\n",
    "I first examine the DuckDB database to understand the structure of the input data. All available tables are listed to confirm that the base table flow_poi is present, and the schema of flow_poi is queried to obtain the full set of column names.\n",
    "\n",
    "From these columns, all fields whose names start with poi_ are selected automatically. These poi_* variables describe the point-of-interest (POI) environment of each grid cell—for example, counts of food, shopping, or entertainment locations nearby. Together they form a POI feature vector, where each element represents the intensity of a POI category and provides a compact numerical description of local urban context.\n",
    "\n",
    "A consistent feature ordering is then defined for later use in NumPy and PyTorch. The feature list begins with the current flow value, followed by all poi_* columns, and ends with four time-encoding features added in the next step: tod_sin, tod_cos, dow_sin, and dow_cos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGRmsMjXCbSZ",
    "outputId": "c842b1f0-3ad8-4d61-a803-867e6ab14c66"
   },
   "outputs": [],
   "source": [
    "info = con.execute(\"PRAGMA table_info('flow_poi');\").fetchall()\n",
    "all_cols = [r[1] for r in info]\n",
    "poi_cols = [c for c in all_cols if c.startswith(\"poi_\")]\n",
    "\n",
    "print(\"lens of POI\", len(poi_cols))\n",
    "print(\"5 poi:\", poi_cols[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building the modeling table flow_feat\n",
    "Next, I construct a cleaned modeling table, flow_feat, directly in DuckDB. Starting from flow_poi, this step turns each grid cell’s half-hourly records into a supervised learning dataset, where the inputs are features at time \n",
    "t and the target is the next half-hour flow for the same cell.\n",
    "\n",
    "Concretely, I standardize the basic indices (day d, time slot t, and grid coordinates x, y) and ensure POI covariates are always defined by filling missing poi_* values with 0. I then add simple calendar features: time_of_day (0–47), dow (0–6), and a flattened time_index = d * 48 + t for chronological ordering.\n",
    "\n",
    "To capture periodicity smoothly, I compute sinusoidal encodings for both time-of-day and day-of-week (tod_sin, tod_cos, dow_sin, dow_cos). Finally, I define the prediction target flow_next as the next half-hour flow within each (x,y) series (using a windowed lead over time). Rows without flow_next—the last time step in each cell—are dropped. The resulting flow_feat table contains the grid identifiers, model inputs (current flow, POI features, and time encodings), the target flow_next, and time_index, ready for temporal splitting and sequence construction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "66a54dd5da574abe8fdbf9e1a411f04d",
      "dc8e16af08dd497686bb86121677c2aa",
      "a775d29f4fd94d979256b7422a7b9a07"
     ]
    },
    "id": "jIO4d6-GDBQ9",
    "outputId": "5d81e95a-ed73-499a-f2c6-a5e822ce3e43"
   },
   "outputs": [],
   "source": [
    "feature_cols = [\"flow\"] + poi_cols + [\"tod_sin\", \"tod_cos\", \"dow_sin\", \"dow_cos\"]\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE flow_feat AS\n",
    "    WITH base AS (\n",
    "        SELECT\n",
    "            d::INT AS d,\n",
    "            t::INT AS t,\n",
    "            x::INT AS x,\n",
    "            y::INT AS y,\n",
    "            flow,\n",
    "            {\", \".join([f\"COALESCE({c}, 0) AS {c}\" for c in poi_cols])},\n",
    "            t AS time_of_day,\n",
    "            d % 7 AS dow,\n",
    "            (d * 48 + t) AS time_index\n",
    "        FROM flow_poi\n",
    "    ),\n",
    "    feat AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            sin(2*PI()*time_of_day/48.0) AS tod_sin,\n",
    "            cos(2*PI()*time_of_day/48.0) AS tod_cos,\n",
    "            sin(2*PI()*dow/7.0)          AS dow_sin,\n",
    "            cos(2*PI()*dow/7.0)          AS dow_cos,\n",
    "            LEAD(flow) OVER (\n",
    "                PARTITION BY x, y\n",
    "                ORDER BY d, t\n",
    "            ) AS flow_next\n",
    "        FROM base\n",
    "    )\n",
    "    SELECT\n",
    "        x,\n",
    "        y,\n",
    "        {\", \".join(feature_cols)},\n",
    "        flow_next,\n",
    "        time_index\n",
    "    FROM feat\n",
    "    WHERE flow_next IS NOT NULL;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train–test split and feature normalization\n",
    "\n",
    "To prepare the data for modeling, a temporal split is applied to the feature table `flow_feat`. Because mobility patterns evolve over time, evaluation should be performed on future periods rather than on randomly shuffled samples. The dataset is therefore split using the global time_index:\n",
    "\n",
    "1. the 80th percentile of time_index is computed across all rows;\n",
    "2. rows with time_index ≤ threshold form the training set (flow_feat_train);\n",
    "3. rows with time_index > threshold form the test set (flow_feat_test).\n",
    "\n",
    "This split trains the model on earlier observations and evaluates it on genuinely later time periods.\n",
    "\n",
    "After splitting, feature-wise means and standard deviations are computed **only from the training set**. These statistics are calculated for each model input feature in feature_cols and are later used to apply z-score normalization to both training and test sequences. Estimating normalization parameters from the training portion only avoids leaking information from the future into the model.\n",
    "\n",
    "The resulting arrays, mean and std, store normalization parameters in a fixed order consistent with the feature layout used by NumPy and PyTorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "c3237904e88c495fb6b7a5cbc0eb8250",
      "c65e99c1a08442bbac7f55982bfa2fce",
      "c24fc8161f9d4cce9d68742e88fb3557",
      "3167a68725e540f0af32f451355cfc6c",
      "20cd043dda8e4005a3dca3dc9ba9f124",
      "8a6a0dc81bfa434a881836b2573748c7",
      "1e8904910b4c434092dbe95e446c6f61",
      "c937d5ff2bbb45a797463a32bf209f93",
      "16a0aa33eb94474da5adb27911544b02",
      "db8c32a1000847a79632f36831d88430",
      "edc51a08a0b74ae387c84b7822eb5ea2",
      "08add841df264cdab83e0e1c339694ae"
     ]
    },
    "id": "LsrqlpuD8WMc",
    "outputId": "c10773a1-bc64-45a6-e28f-9755e5a4059f"
   },
   "outputs": [],
   "source": [
    "# 80% threshold\n",
    "import numpy as np\n",
    "\n",
    "threshold = con.execute(\"\"\"\n",
    "    SELECT quantile(time_index, 0.8) FROM flow_feat;\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE flow_feat_train AS\n",
    "    SELECT * FROM flow_feat\n",
    "    WHERE time_index <= ?;\n",
    "\"\"\", [threshold])\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE flow_feat_test AS\n",
    "    SELECT * FROM flow_feat\n",
    "    WHERE time_index > ?;\n",
    "\"\"\", [threshold])\n",
    "\n",
    "# mean / std\n",
    "mean_row = con.execute(f\"\"\"\n",
    "    SELECT {\", \".join([f\"avg({c}) AS {c}\" for c in feature_cols])}\n",
    "    FROM flow_feat_train;\n",
    "\"\"\").fetchnumpy()\n",
    "\n",
    "std_row = con.execute(f\"\"\"\n",
    "    SELECT {\", \".join([f\"stddev_samp({c}) AS {c}\" for c in feature_cols])}\n",
    "    FROM flow_feat_train;\n",
    "\"\"\").fetchnumpy()\n",
    "\n",
    "mean = np.array([mean_row[c][0] for c in feature_cols], dtype=\"float32\")\n",
    "std  = np.array([std_row[c][0]  for c in feature_cols], dtype=\"float32\") + 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1L2wF51qKgZ"
   },
   "source": [
    "## 3. Sequence Construction\n",
    "Training sequences are constructed using three hyperparameters: SEQ_LEN = 8, STRIDE = 4, and BATCH_SIZE = 1024. With SEQ_LEN = 8, each sample consists of the most recent eight half-hour observations for a given grid cell, corresponding to a 4-hour historical window. A STRIDE of 4 shifts the sliding window forward by four time steps (two hours), preventing consecutive samples from being nearly identical. BATCH_SIZE = 1024 determines how many sequences are processed together in each mini-batch, providing a balance between computational efficiency and training stability.\n",
    "\n",
    "Sequence generation begins from the tables flow_feat_train and flow_feat_test, with sequences built independently for each grid cell \n",
    "(x,y). Only cells appearing at least eight times are retained, ensuring that a full sequence of length SEQ_LEN is available. For each eligible cell, its rows are sorted by the global time_index to form an ordered time series. The columns listed in feature_cols are then extracted and standardized using the mean and standard deviation from the training set, placing all features on a comparable scale.\n",
    "\n",
    "A fixed-length sliding window of size 8 is applied to each standardized cell-level time series, with window start positions at \n",
    "i=0,4,8,…, reflecting the chosen stride. Each window produces an input sequence consisting of eight consecutive half-hour records, and the prediction target is defined as the flow_next value associated with the final row in the window. Conceptually, each training example captures a 4-hour history and asks the model to predict the flow in the subsequent half-hour.\n",
    "\n",
    "All resulting examples are grouped into mini-batches of size 1024. Each batch tensor X_batch has shape \n",
    "[1024,8,feature_dim], containing 1024 standardized sequences of length 8. The corresponding target vector y_batch has shape [1024], holding the next-step flow values. Both the linear baseline model and the LSTM model consume the same batch format during training and evaluation, meaning that any performance differences arise solely from how the two architectures interpret the same sequence input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwgYxNk38jC5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "SEQ_LEN   = 8\n",
    "BATCH_SIZE = 1024\n",
    "STRIDE    = 4\n",
    "\n",
    "def seq_batch_generator(table_name, batch_size=BATCH_SIZE, seq_len=SEQ_LEN, max_cells=None):\n",
    "    \"\"\"\n",
    "    Generate sequence batches from flow_feat_train / flow_feat_test.\n",
    "\n",
    "    X_batch: [batch, seq_len, feature_dim]\n",
    "    y_batch: [batch]\n",
    "    \"\"\"\n",
    "    cells = con.execute(f\"\"\"\n",
    "        SELECT x, y\n",
    "        FROM {table_name}\n",
    "        GROUP BY x, y\n",
    "        HAVING COUNT(*) >= {seq_len}\n",
    "    \"\"\").fetchall()\n",
    "\n",
    "    if max_cells is not None:\n",
    "        cells = cells[:max_cells]\n",
    "\n",
    "    print(f\"{table_name}: {len(cells)} cells with >= {seq_len} records\")\n",
    "\n",
    "    for (x_val, y_val) in cells:\n",
    "        res = con.execute(f\"\"\"\n",
    "            SELECT time_index, {\", \".join(feature_cols)}, flow_next\n",
    "            FROM {table_name}\n",
    "            WHERE x = ? AND y = ?\n",
    "            ORDER BY time_index\n",
    "        \"\"\", [x_val, y_val]).fetchnumpy()\n",
    "\n",
    "        n = len(res[\"flow_next\"])\n",
    "        if n < seq_len:\n",
    "            continue\n",
    "\n",
    "        feats = np.column_stack([res[c] for c in feature_cols]).astype(\"float32\")\n",
    "        feats = (feats - mean) / std\n",
    "\n",
    "        y_vec = res[\"flow_next\"].astype(\"float32\")\n",
    "\n",
    "        X_buf, y_buf = [], []\n",
    "\n",
    "        for i in range(0, n - seq_len + 1, STRIDE):\n",
    "            X_seq = feats[i:i+seq_len]           # [seq_len, F]\n",
    "            y_target = y_vec[i + seq_len - 1]    # scalar\n",
    "\n",
    "            X_buf.append(X_seq)\n",
    "            y_buf.append(y_target)\n",
    "\n",
    "            if len(X_buf) == batch_size:\n",
    "                yield np.stack(X_buf), np.array(y_buf)\n",
    "                X_buf, y_buf = [], []\n",
    "\n",
    "        if len(X_buf) > 0:\n",
    "            yield np.stack(X_buf), np.array(y_buf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Linear sequence baseline\n",
    "\n",
    "To provide a simple point of comparison, we also include a linear baseline\n",
    "model. Instead of using a recurrent structure, this model treats the entire\n",
    "input sequence as a single flat vector. All `SEQ_LEN` feature rows are\n",
    "concatenated into one long input, and the model applies a single fully\n",
    "connected layer to map this vector directly to a predicted next-step flow.\n",
    "\n",
    "This baseline has no notion of temporal order or temporal dependency. It can\n",
    "only learn a weighted combination of the raw features but cannot model how\n",
    "patterns evolve over time. As a result, it serves as a useful reference for\n",
    "evaluating whether the LSTM’s recurrent structure truly provides additional\n",
    "predictive power.\n",
    "\n",
    "Despite its simplicity, the linear model is fast to train and helps quantify\n",
    "the value of incorporating temporal dynamics into the prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "\n",
    "class FlowLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F]\n",
    "        out, _ = self.lstm(x)          # out: [B, L, H]\n",
    "        last_hidden = out[:, -1, :]    # [B, H] -> last time step\n",
    "        y_pred = self.fc(last_hidden)  # [B, 1]\n",
    "        return y_pred.squeeze(-1)      # [B]\n",
    "\n",
    "model = FlowLSTM(input_dim, hidden_dim, num_layers).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_mse_seq(table_name: str) -> float:\n",
    "    model.eval()\n",
    "    sq_sum = 0.0\n",
    "    n = 0\n",
    "    for X_batch, y_batch in seq_batch_generator(table_name, batch_size=BATCH_SIZE, seq_len=SEQ_LEN):\n",
    "        xb = torch.from_numpy(X_batch).to(device)  # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)  # [B]\n",
    "        pred = model(xb)                           # [B]\n",
    "        sq_sum += ((pred - yb) ** 2).sum().item()\n",
    "        n += len(yb)\n",
    "    return sq_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 LSTM model\n",
    "\n",
    "The first predictive model we use is an LSTM-based sequence model designed to\n",
    "capture temporal structure in mobility flows. Each input sample is a\n",
    "fixed-length sequence containing `SEQ_LEN` consecutive half-hour records for a\n",
    "single grid cell. Each record has the full feature vector consisting of the\n",
    "flow value, POI-based attributes, and the time-encoding variables.\n",
    "\n",
    "The LSTM processes these sequences one time step at a time. As it moves through\n",
    "the eight input steps, it maintains a hidden state that summarizes the\n",
    "information accumulated so far. After the final time step, the hidden state\n",
    "represents the model’s understanding of the recent history of the cell.\n",
    "\n",
    "To make a prediction, we take this final hidden state and feed it into a\n",
    "fully connected layer that outputs a single value: the predicted next-step\n",
    "flow. This structure allows the model to learn temporal dependencies,\n",
    "non-linear feature interactions, and recurring movement patterns across days.\n",
    "\n",
    "The LSTM used here has:\n",
    "- batch-first input format,\n",
    "- a hidden size of 64,\n",
    "- two stacked recurrent layers,\n",
    "- and a final linear layer that maps the hidden representation into a scalar\n",
    "  prediction.\n",
    "\n",
    "The model is trained end-to-end with the Adam optimizer and mean squared error\n",
    "as the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "\n",
    "class FlowLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F]\n",
    "        out, _ = self.lstm(x)        \n",
    "        last_hidden = out[:, -1, :]   \n",
    "        y_pred = self.fc(last_hidden)  \n",
    "        return y_pred.squeeze(-1)     \n",
    "\n",
    "\n",
    "class LinearSeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.fc = nn.Linear(input_dim * seq_len, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F]\n",
    "        B, L, F = x.shape\n",
    "        x_flat = x.reshape(B, L * F)  \n",
    "        y_pred = self.fc(x_flat)       \n",
    "        return y_pred.squeeze(-1)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJYSw8Kop4LP"
   },
   "source": [
    "## 5. Training\n",
    "\n",
    "### 5.1 Linear baseline model\n",
    "\n",
    "The linear baseline model LinearSeqModel is a simple fully connected\n",
    "regressor that ignores temporal order within the input sequence. Each input\n",
    "batch X_batch initially has shape [B, L, F], where B is the batch size,\n",
    "L = SEQ_LEN is the number of time steps, and F is the feature dimension.\n",
    "Before feeding the data into the model, the tensor is reshaped to\n",
    "[B, L * F], so that all time steps in the sequence are concatenated into a\n",
    "single flat feature vector.\n",
    "\n",
    "The model consists of one linear layer nn.Linear(input_dim * seq_len, 1)\n",
    "that maps this flattened sequence to a single scalar prediction. Training\n",
    "uses the Adam optimizer with a learning rate of 1e-3 and mean squared error\n",
    "(MSE) as the loss function. For each epoch, the code iterates over all\n",
    "sequence batches generated from the flow_feat_train table, performs\n",
    "forward and backward passes, and updates the model parameters. The training\n",
    "loop also accumulates the sum of squared errors to compute the training MSE.\n",
    "\n",
    "After each epoch, the helper function evaluate_mse_linear is called on the\n",
    "flow_feat_test table to compute the test MSE using the same batching logic.\n",
    "This function runs the model in evaluation mode, iterates over all test\n",
    "batches, and returns the average squared error across all samples. Finally,\n",
    "the trained linear model weights are saved to\n",
    "flow_linear_seq_epoch8.pth as the linear baseline checkpoint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKdheDwO-k0N",
    "outputId": "11dfb98f-78ad-49c3-a892-40ce212405b6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LinearSeqModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, seq_len: int):\n",
    "        \"\"\"\n",
    "        input_dim: len(feature_cols)\n",
    "        seq_len  : SEQ_LEN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.fc = nn.Linear(input_dim * seq_len, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, L*F]\n",
    "        \"\"\"\n",
    "        y_pred = self.fc(x)          # [B, 1]\n",
    "        return y_pred.squeeze(-1)    # [B]\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "\n",
    "lin_model = LinearSeqModel(input_dim=input_dim, seq_len=SEQ_LEN).to(device)\n",
    "lin_loss_fn = nn.MSELoss()\n",
    "lin_optimizer = torch.optim.Adam(lin_model.parameters(), lr=1e-3)\n",
    "\n",
    "print(lin_model)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mse_linear(model, table_name: str, max_cells=None) -> float:\n",
    "    model.eval()\n",
    "    sq_sum = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        table_name,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=max_cells\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)    # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)    # [B]\n",
    "\n",
    "        xb = xb.reshape(xb.shape[0], -1)             # [B, L*F]\n",
    "\n",
    "        pred = model(xb)                             # [B]\n",
    "        sq_sum += ((pred - yb) ** 2).sum().item()\n",
    "        n += len(yb)\n",
    "\n",
    "    return sq_sum / n\n",
    "\n",
    "\n",
    "EPOCHS_LIN = 8\n",
    "\n",
    "for epoch in range(1, EPOCHS_LIN + 1):\n",
    "    lin_model.train()\n",
    "    train_sq_sum = 0.0\n",
    "    train_n = 0\n",
    "    batch_idx = 0\n",
    "\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        \"flow_feat_train\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=None\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)    # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)    # [B]\n",
    "\n",
    "        # flatten [B, L*F]\n",
    "        xb = xb.reshape(xb.shape[0], -1)\n",
    "\n",
    "        lin_optimizer.zero_grad()\n",
    "        pred = lin_model(xb)                         # [B]\n",
    "        loss = lin_loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        lin_optimizer.step()\n",
    "\n",
    "        train_sq_sum += ((pred.detach() - yb) ** 2).sum().item()\n",
    "        train_n += len(yb)\n",
    "\n",
    "        batch_idx += 1\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"[Linear] Epoch {epoch:02d} | Processed {batch_idx} batches\")\n",
    "\n",
    "    #  train / test MSE\n",
    "    train_mse = train_sq_sum / train_n\n",
    "    test_mse = evaluate_mse_linear(lin_model, \"flow_feat_test\", max_cells=None)\n",
    "\n",
    "    print(f\"[Linear] Epoch {epoch:02d} | Train MSE {train_mse:.4f} | Test MSE {test_mse:.4f}\")\n",
    "\n",
    "torch.save(\n",
    "    lin_model.state_dict(),\n",
    "    \"/content/drive/MyDrive/MOBILITY/flow_linear_seq_epoch8.pth\"\n",
    ")\n",
    "print(\"Saved linear baseline model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/006.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 LSTM training and checkpointing\n",
    "\n",
    "The second training loop trains the LSTM-based sequence model defined earlier\n",
    "in the notebook. In contrast to the linear baseline, the LSTM takes input\n",
    "batches of shape [B, L, F] directly and processes the sequence along the\n",
    "time dimension, maintaining a hidden state to capture temporal dependencies.\n",
    "\n",
    "The helper function evaluate_mse_seq mirrors the linear evaluation function,\n",
    "but it calls the sequence model directly on tensors of shape [B, L, F]\n",
    "without flattening. It runs the model in evaluation mode, iterates over all\n",
    "batches from the specified DuckDB table, and returns the mean squared error\n",
    "over all samples.\n",
    "\n",
    "The main training loop runs for EPOCHS = 8. For each epoch, the model is set\n",
    "to training mode, and batches are drawn from the flow_feat_train table using\n",
    "seq_batch_generator. For every batch, the code moves the data to the\n",
    "selected device (CPU or GPU), performs a forward pass through the LSTM,\n",
    "computes the MSE loss, backpropagates the gradients, and updates the\n",
    "parameters with the chosen optimizer. The loop accumulates the sum of squared\n",
    "errors to compute the epoch-level training MSE, and every 100 batches it\n",
    "prints a progress message.\n",
    "\n",
    "At the end of each epoch, evaluate_mse_seq is called on the\n",
    "flow_feat_test table to obtain the test MSE. The code then saves a\n",
    "checkpoint file under checkpoints_lstm/, containing the current epoch index,\n",
    "the model and optimizer state dictionaries, and the train/test MSE values.\n",
    "This allows intermediate models to be restored later if needed. After the\n",
    "final epoch, the model’s state dictionary is also saved separately to\n",
    "flow_lstm_final.pth as the final LSTM checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4MAIVJP-kxt",
    "outputId": "fdb640ff-5553-4940-9320-af3d1a706229"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# checkpoint\n",
    "ckpt_dir = \"/content/drive/MyDrive/MOBILITY/checkpoints_lstm\"\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# ----- training loop ----- checkpoint\n",
    "EPOCHS = 8\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mse_seq(table_name: str, max_cells=None) -> float:\n",
    "    model.eval()\n",
    "    sq_sum = 0.0\n",
    "    n = 0\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        table_name,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=max_cells\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)  # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)  # [B]\n",
    "        pred = model(xb)                           # [B]\n",
    "        sq_sum += ((pred - yb) ** 2).sum().item()\n",
    "        n += len(yb)\n",
    "    return sq_sum / n\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_sq_sum = 0.0\n",
    "    train_n = 0\n",
    "\n",
    "    batch_idx = 0\n",
    "\n",
    "    # Here you can set max_cells for debugging; set to None for full data\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        \"flow_feat_train\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=None\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)\n",
    "        yb = torch.from_numpy(y_batch).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_sq_sum += ((pred.detach() - yb) ** 2).sum().item()\n",
    "        train_n += len(yb)\n",
    "\n",
    "        batch_idx += 1\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch:02d} | Processed {batch_idx} batches so far\")\n",
    "\n",
    "    train_mse = train_sq_sum / train_n\n",
    "    test_mse = evaluate_mse_seq(\"flow_feat_test\", max_cells=None)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train MSE {train_mse:.4f} | Test MSE {test_mse:.4f}\")\n",
    "\n",
    "    ckpt_path = os.path.join(ckpt_dir, f\"flow_lstm_epoch{epoch:02d}.pth\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_mse\": train_mse,\n",
    "            \"test_mse\": test_mse,\n",
    "        },\n",
    "        ckpt_path,\n",
    "    )\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "\n",
    "final_path = \"/content/drive/MyDrive/MOBILITY/flow_lstm_final.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(f\"Saved final model to {final_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/007.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Spatial visualization\n",
    "\n",
    "To see where (and when) the model performs well, I visualize predictions across the grid for a day 64 at time slot t=21 (randomly choosed). For this time point, I reconstruct the required history sequence for each grid cell, run the trained model to predict the next-step flow, and compare predictions against the observed values.\n",
    "\n",
    "The visualization is produced in two modes:\n",
    "\n",
    "\n",
    "### 6.1 Single time slice\n",
    "\n",
    "- Identify all grid cells that have a valid next-step target at this time point (i.e., flow_next is available).\n",
    "\n",
    "- For each such cell, retrieve the preceding SEQ_LEN records to form its complete input history.\n",
    "\n",
    "- Run the model and map three spatial surfaces: true next-step flow, predicted next-step flow, absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-5ESx1W72Lf",
    "outputId": "22827492-36ff-4a93-ee67-21e047555b19"
   },
   "outputs": [],
   "source": [
    "d0 = 64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_t = 16\n",
    "window_len = 8\n",
    "end_t = start_t + window_len - 1\n",
    "\n",
    "window_df = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        x,\n",
    "        y,\n",
    "        (time_index % 48) AS t,\n",
    "        flow\n",
    "    FROM flow_feat_test\n",
    "    WHERE (time_index / 48)::INT = ?\n",
    "      AND (time_index % 48) BETWEEN ? AND ?\n",
    "\"\"\", [d0, start_t, end_t]).fetchdf()\n",
    "\n",
    "print(window_df.head())\n",
    "print(\"records have =\", len(window_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXiMttw7MC91",
    "outputId": "0c33ada2-4767-42f9-b615-7cbb60f19c07"
   },
   "outputs": [],
   "source": [
    "t_plot = end_t\n",
    "\n",
    "snap_true = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "        x,\n",
    "        y,\n",
    "        flow_next AS target,\n",
    "        time_index\n",
    "    FROM flow_feat_test\n",
    "    WHERE (time_index / 48)::INT = ?\n",
    "      AND (time_index % 48) = ?;\n",
    "\"\"\", [d0, t_plot]).fetchdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0mmrNbhMLsV",
    "outputId": "8a220176-9fe2-434a-d196-35e427b6973d"
   },
   "outputs": [],
   "source": [
    "X_list, target_list, x_list, y_list = [], [], [], []\n",
    "\n",
    "for idx, row in snap_true.iterrows():\n",
    "    x0 = int(row[\"x\"])\n",
    "    y0 = int(row[\"y\"])\n",
    "    T  = int(row[\"time_index\"])\n",
    "    y_true = float(row[\"target\"])\n",
    "\n",
    "    seq_df = con.execute(f\"\"\"\n",
    "        SELECT time_index, {\", \".join(feature_cols)}\n",
    "        FROM (\n",
    "            SELECT time_index, {\", \".join(feature_cols)}\n",
    "            FROM flow_feat_test\n",
    "            WHERE x = ? AND y = ?\n",
    "              AND (time_index / 48)::INT = ?\n",
    "              AND time_index <= ?\n",
    "            ORDER BY time_index DESC\n",
    "            LIMIT ?\n",
    "        )\n",
    "        ORDER BY time_index;\n",
    "    \"\"\", [x0, y0, d0, T, SEQ_LEN]).fetchdf()\n",
    "\n",
    "    if len(seq_df) < SEQ_LEN:\n",
    "        continue\n",
    "\n",
    "    feats = seq_df[feature_cols].to_numpy(dtype=\"float32\")\n",
    "    feats_norm = (feats - mean) / std\n",
    "\n",
    "    X_list.append(feats_norm)\n",
    "    target_list.append(y_true)\n",
    "    x_list.append(x0)\n",
    "    y_list.append(y0)\n",
    "\n",
    "print(\"usable cells with full 8-step history:\", len(X_list))\n",
    "\n",
    "X = np.stack(X_list).astype(\"float32\")       # [N, L, F]\n",
    "y_true_arr = np.array(target_list, dtype=\"float32\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xb = torch.from_numpy(X).to(device)     # [N, L, F]\n",
    "    pred_arr = model(xb).cpu().numpy()      # [N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kqSLaZjOgN4"
   },
   "outputs": [],
   "source": [
    "snap = pd.DataFrame({\n",
    "    \"x\": x_list,\n",
    "    \"y\": y_list,\n",
    "    \"flow_true\": y_true_arr,     # true next-step flow\n",
    "    \"flow_pred\": pred_arr,       # LSTM predicted next-step flow\n",
    "})\n",
    "snap[\"err_abs\"] = np.abs(snap[\"flow_pred\"] - snap[\"flow_true\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "uBLQ7zR2OiAx",
    "outputId": "3b76a674-d5cf-4587-ab7d-c75047eb81f3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vmin = np.percentile(snap[\"flow_true\"], 5)\n",
    "vmax = np.percentile(snap[\"flow_true\"], 95)\n",
    "\n",
    "err_max = np.percentile(snap[\"err_abs\"], 95)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax = axes[0]\n",
    "sc0 = ax.scatter(\n",
    "    snap[\"x\"], snap[\"y\"],\n",
    "    c=snap[\"flow_true\"],\n",
    "    s=10,\n",
    "    cmap=\"plasma\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "ax.set_title(\"True next-step flow\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(False)\n",
    "plt.colorbar(sc0, ax=ax, label=\"flow_true\")\n",
    "\n",
    "ax = axes[1]\n",
    "sc1 = ax.scatter(\n",
    "    snap[\"x\"], snap[\"y\"],\n",
    "    c=snap[\"flow_pred\"],\n",
    "    s=10,\n",
    "    cmap=\"plasma\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "ax.set_title(\"LSTM predicted next-step flow\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(False)\n",
    "plt.colorbar(sc1, ax=ax, label=\"flow_pred\")\n",
    "\n",
    "ax = axes[2]\n",
    "sc2 = ax.scatter(\n",
    "    snap[\"x\"], snap[\"y\"],\n",
    "    c=snap[\"err_abs\"],\n",
    "    s=10,\n",
    "    cmap=\"magma\",\n",
    "    vmin=0,\n",
    "    vmax=err_max\n",
    ")\n",
    "ax.set_title(\"|pred − true|\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(False)\n",
    "plt.colorbar(sc2, ax=ax, label=\"abs error\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "\n",
    "minutes = t_plot * 30\n",
    "hh = minutes // 60\n",
    "mm = minutes % 60\n",
    "plt.suptitle(f\"Day {d0}, t={t_plot} (~{hh:02d}:{mm:02d}) – next-step flow\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Multiple time slices\n",
    "\n",
    "Select several time slots on the same day.\n",
    "\n",
    "- For each time slot, repeat the single-slice procedure: build SEQ_LEN histories per cell, predict the next-step flow, and compute errors.\n",
    "\n",
    "- Stack the resulting maps in a grid: the first row shows true flows, the second row shows predictions, and the third row shows absolute errors.\n",
    "\n",
    "- Use shared color scales within each row so patterns can be compared consistently across times.\n",
    "\n",
    "These maps highlight spatial heterogeneity in both mobility intensity and predictive performance. They make it easy to spot when the model breaks down, which areas are consistently more predictable, and how flow patterns shift over the course of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjhGCMKjOxjP",
    "outputId": "5af24f16-c7ae-41ba-d277-6099a8e7c2c9"
   },
   "outputs": [],
   "source": [
    "d0 = 64\n",
    "\n",
    "t_list = [8, 12, 16, 20, 24, 28]\n",
    "\n",
    "snap_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for t_plot in t_list:\n",
    "    snap_true = con.execute(\"\"\"\n",
    "        SELECT\n",
    "            x,\n",
    "            y,\n",
    "            flow_next AS target,\n",
    "            time_index\n",
    "        FROM flow_feat_test\n",
    "        WHERE (time_index / 48)::INT = ?\n",
    "          AND (time_index % 48) = ?;\n",
    "    \"\"\", [d0, t_plot]).fetchdf()\n",
    "\n",
    "    X_list, target_list, x_list, y_list = [], [], [], []\n",
    "\n",
    "    for idx, row in snap_true.iterrows():\n",
    "        x0 = int(row[\"x\"])\n",
    "        y0 = int(row[\"y\"])\n",
    "        T  = int(row[\"time_index\"])\n",
    "        y_true = float(row[\"target\"])\n",
    "\n",
    "        seq_df = con.execute(f\"\"\"\n",
    "            SELECT time_index, {\", \".join(feature_cols)}\n",
    "            FROM (\n",
    "                SELECT time_index, {\", \".join(feature_cols)}\n",
    "                FROM flow_feat_test\n",
    "                WHERE x = ? AND y = ?\n",
    "                  AND (time_index / 48)::INT = ?\n",
    "                  AND time_index <= ?\n",
    "                ORDER BY time_index DESC\n",
    "                LIMIT ?\n",
    "            )\n",
    "            ORDER BY time_index;\n",
    "        \"\"\", [x0, y0, d0, T, SEQ_LEN]).fetchdf()\n",
    "\n",
    "        if len(seq_df) < SEQ_LEN:\n",
    "            continue\n",
    "\n",
    "        feats = seq_df[feature_cols].to_numpy(dtype=\"float32\")\n",
    "        feats_norm = (feats - mean) / std\n",
    "\n",
    "        X_list.append(feats_norm)\n",
    "        target_list.append(y_true)\n",
    "        x_list.append(x0)\n",
    "        y_list.append(y0)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        print(f\"t={t_plot} no enough\")\n",
    "        continue\n",
    "\n",
    "    X = np.stack(X_list).astype(\"float32\")\n",
    "    y_true_arr = np.array(target_list, dtype=\"float32\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        xb = torch.from_numpy(X).to(device)\n",
    "        y_pred_arr = model(xb).cpu().numpy()\n",
    "\n",
    "    snap = pd.DataFrame({\n",
    "        \"x\": x_list,\n",
    "        \"y\": y_list,\n",
    "        \"flow_true\": y_true_arr,\n",
    "        \"flow_pred\": y_pred_arr,\n",
    "    })\n",
    "    snap[\"err_abs\"] = np.abs(snap[\"flow_pred\"] - snap[\"flow_true\"])\n",
    "    snap[\"t_plot\"] = t_plot\n",
    "\n",
    "    snap_list.append(snap)\n",
    "\n",
    "print(\"usable time points\", len(snap_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "id": "lMUR-w1_eKmJ",
    "outputId": "dae2130c-2fad-4a07-d38e-e69819bfedbd"
   },
   "outputs": [],
   "source": [
    "all_snap = pd.concat(snap_list, ignore_index=True)\n",
    "vmin = np.percentile(all_snap[\"flow_true\"], 5)\n",
    "vmax = np.percentile(all_snap[\"flow_true\"], 95)\n",
    "err_max = np.percentile(all_snap[\"err_abs\"], 95)\n",
    "\n",
    "n_times = len(snap_list)\n",
    "snap_list_sorted = sorted(snap_list, key=lambda s: s[\"t_plot\"].iloc[0])\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    3, n_times,\n",
    "    figsize=(3.0 * n_times, 8),\n",
    "    sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "sc_true = None\n",
    "sc_err = None\n",
    "\n",
    "for j, snap in enumerate(snap_list_sorted):\n",
    "    t_plot = snap[\"t_plot\"].iloc[0]\n",
    "\n",
    "    ax = axes[0, j]\n",
    "    sc_true = ax.scatter(\n",
    "        snap[\"x\"], snap[\"y\"],\n",
    "        c=snap[\"flow_true\"],\n",
    "        s=5,\n",
    "        cmap=\"plasma\",\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax.set_title(f\"t={t_plot} True\", fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    ax = axes[1, j]\n",
    "    ax.scatter(\n",
    "        snap[\"x\"], snap[\"y\"],\n",
    "        c=snap[\"flow_pred\"],\n",
    "        s=5,\n",
    "        cmap=\"plasma\",\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax.set_title(f\"t={t_plot} Pred\", fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    ax = axes[2, j]\n",
    "    sc_err = ax.scatter(\n",
    "        snap[\"x\"], snap[\"y\"],\n",
    "        c=snap[\"err_abs\"],\n",
    "        s=5,\n",
    "        cmap=\"magma\",\n",
    "        vmin=0, vmax=err_max\n",
    "    )\n",
    "    ax.set_title(f\"t={t_plot} |Pred−True|\", fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(False)\n",
    "\n",
    "for j in range(n_times):\n",
    "    axes[2, j].set_xlabel(\"x\")\n",
    "for i in range(3):\n",
    "    axes[i, 0].set_ylabel(\"y\")\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    left=0.06, right=0.9,\n",
    "    top=0.9, bottom=0.08,\n",
    "    wspace=0.05, hspace=0.12\n",
    ")\n",
    "\n",
    "cbar1 = fig.colorbar(\n",
    "    sc_true,\n",
    "    ax=axes[0:2, -1],\n",
    "    fraction=0.046,\n",
    "    pad=0.02\n",
    ")\n",
    "cbar1.set_label(\"flow\")\n",
    "\n",
    "cbar2 = fig.colorbar(\n",
    "    sc_err,\n",
    "    ax=axes[2, -1],\n",
    "    fraction=0.046,\n",
    "    pad=0.04\n",
    ")\n",
    "cbar2.set_label(\"abs error\")\n",
    "\n",
    "plt.suptitle(f\"Day {d0} – 6 time steps: True / Pred / Error\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/003.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "The results demonstrate that temporal modeling is essential for predicting\n",
    "grid-based mobility flows. The linear baseline, which treats the input sequence\n",
    "as a single flattened vector, fails to capture temporal structure: its test MSE\n",
    "is more than two orders of magnitude worse than that of the LSTM. In contrast,\n",
    "the LSTM achieves stable performance (train MSE ≈ 3.79, test MSE ≈ 4.15),\n",
    "indicating that it successfully learns short-term temporal dependencies in the\n",
    "flow dynamics.\n",
    "\n",
    "Spatial visualizations further confirm this pattern. Across six representative\n",
    "time steps on Day 64, the LSTM reproduces the broad spatial structure of flow,\n",
    "accurately matching both low-flow regions and the major concentration zones.\n",
    "Prediction errors are primarily concentrated in high-intensity areas—locations\n",
    "where flow is both larger in magnitude and more volatile. This suggests that\n",
    "the LSTM captures routine, low-variance mobility well, while sudden spikes or\n",
    "irregular flow patterns remain harder to model.\n",
    "\n",
    "Overall, the experiment shows that:\n",
    "1. Temporal information is crucial for mobility forecasting.\n",
    "2. Even a relatively small LSTM (hidden size 64, two layers) is sufficient to\n",
    "   outperform non-temporal baselines by a wide margin.\n",
    "3. The remaining errors are spatially structured, pointing toward opportunities\n",
    "   for future extensions such as attention mechanisms or spatial graph models.\n",
    "\n",
    "The LSTM therefore provides a strong foundation for next-step mobility\n",
    "prediction, and the spatial evaluation highlights where more advanced models\n",
    "may yield additional gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08add841df264cdab83e0e1c339694ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "16a0aa33eb94474da5adb27911544b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "1e8904910b4c434092dbe95e446c6f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c937d5ff2bbb45a797463a32bf209f93",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16a0aa33eb94474da5adb27911544b02",
      "value": 100
     }
    },
    "20cd043dda8e4005a3dca3dc9ba9f124": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "3167a68725e540f0af32f451355cfc6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20cd043dda8e4005a3dca3dc9ba9f124",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a6a0dc81bfa434a881836b2573748c7",
      "value": 100
     }
    },
    "66a54dd5da574abe8fdbf9e1a411f04d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc8e16af08dd497686bb86121677c2aa",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a775d29f4fd94d979256b7422a7b9a07",
      "value": 100
     }
    },
    "8a6a0dc81bfa434a881836b2573748c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "a775d29f4fd94d979256b7422a7b9a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "c24fc8161f9d4cce9d68742e88fb3557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "c3237904e88c495fb6b7a5cbc0eb8250": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c65e99c1a08442bbac7f55982bfa2fce",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c24fc8161f9d4cce9d68742e88fb3557",
      "value": 100
     }
    },
    "c65e99c1a08442bbac7f55982bfa2fce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "c937d5ff2bbb45a797463a32bf209f93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "db8c32a1000847a79632f36831d88430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edc51a08a0b74ae387c84b7822eb5ea2",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08add841df264cdab83e0e1c339694ae",
      "value": 100
     }
    },
    "dc8e16af08dd497686bb86121677c2aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "edc51a08a0b74ae387c84b7822eb5ea2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
