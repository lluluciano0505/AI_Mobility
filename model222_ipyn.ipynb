{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Spatial Flow Prediction: True Values, Predictions, and Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data and feature construction\n",
    "\n",
    "We start from a DuckDB database `mobility.duckdb` stored in Google Drive.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "C-yF-ngOCOvk",
    "outputId": "ac3aeb5d-dc0f-4724-d147-92e75b80c069"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "con = duckdb.connect(\"/content/drive/MyDrive/MOBILITY/mobility.duckdb\")\n",
    "\n",
    "con.execute(\"SHOW TABLES;\").fetchdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Inspecting the base table\n",
    "\n",
    "We begin by examining the DuckDB database to understand the structure of the\n",
    "input data. First, we list all available tables and confirm that the base table\n",
    "`flow_poi` is present. We then query the schema of `flow_poi` to obtain the\n",
    "names of all its columns.\n",
    "\n",
    "From these column names, we automatically extract all features whose names\n",
    "start with `poi_`. These `poi_*` columns represent POI-based attributes for\n",
    "each grid cell (for example, counts of different POI types). Collecting them\n",
    "programmatically avoids hard-coding a long list of POI fields.\n",
    "\n",
    "Finally, we define a consistent feature ordering for later use in NumPy and\n",
    "PyTorch. The feature list starts with the current `flow` value, followed by\n",
    "all `poi_*` columns, and ends with four time-encoding features that we will\n",
    "add next: `tod_sin`, `tod_cos`, `dow_sin`, and `dow_cos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGRmsMjXCbSZ",
    "outputId": "c842b1f0-3ad8-4d61-a803-867e6ab14c66"
   },
   "outputs": [],
   "source": [
    "info = con.execute(\"PRAGMA table_info('flow_poi');\").fetchall()\n",
    "all_cols = [r[1] for r in info]\n",
    "poi_cols = [c for c in all_cols if c.startswith(\"poi_\")]\n",
    "\n",
    "print(\"lens of POI\", len(poi_cols))\n",
    "print(\"5 poi:\", poi_cols[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Building the modeling table `flow_feat`\n",
    "\n",
    "Next, we construct a cleaned and feature-rich modeling table called\n",
    "`flow_feat` directly inside DuckDB. This table transforms the raw records\n",
    "from `flow_poi` into supervised learning examples that can be consumed by\n",
    "sequence models.\n",
    "\n",
    "The construction proceeds in two steps. In the first step, we:\n",
    "\n",
    "- cast the day (`d`), time (`t`), and grid indices (`x`, `y`) to integers;\n",
    "- replace missing values in all `poi_*` columns with 0, so that POI features\n",
    "  are well-defined for every cell;\n",
    "- define `time_of_day = t` as a half-hour index from 0 to 47;\n",
    "- define `dow = d % 7` as a day-of-week index from 0 to 6;\n",
    "- create a global `time_index = d * 48 + t` that flattens `(day, half-hour)`\n",
    "  into a single time axis.\n",
    "\n",
    "In the second step, we enrich each row with temporal encodings and a prediction\n",
    "target:\n",
    "\n",
    "- we compute sinusoidal encodings of time-of-day,\n",
    "  `tod_sin` and `tod_cos`, to represent the 48 half-hour slots within a day\n",
    "  as points on a circle;\n",
    "- we compute sinusoidal encodings of day-of-week,\n",
    "  `dow_sin` and `dow_cos`, to represent the weekly cycle;\n",
    "- we define `flow_next` as the next half-hour flow for the same grid cell,\n",
    "  using a window function over each `(x, y)` time series ordered by `(d, t)`.\n",
    "\n",
    "Finally, we select the grid indices (`x`, `y`), all model input features\n",
    "(`flow`, all `poi_*` columns, and the four time encodings), the target\n",
    "`flow_next`, and the global `time_index`. Rows where `flow_next` is missing\n",
    "(i.e., the last time step in a cell’s sequence) are dropped. The resulting\n",
    "`flow_feat` table is a clean, fully-specified dataset ready for temporal\n",
    "train/test splitting and sequence construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "66a54dd5da574abe8fdbf9e1a411f04d",
      "dc8e16af08dd497686bb86121677c2aa",
      "a775d29f4fd94d979256b7422a7b9a07"
     ]
    },
    "id": "jIO4d6-GDBQ9",
    "outputId": "5d81e95a-ed73-499a-f2c6-a5e822ce3e43"
   },
   "outputs": [],
   "source": [
    "feature_cols = [\"flow\"] + poi_cols + [\"tod_sin\", \"tod_cos\", \"dow_sin\", \"dow_cos\"]\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE flow_feat AS\n",
    "    WITH base AS (\n",
    "        SELECT\n",
    "            d::INT AS d,\n",
    "            t::INT AS t,\n",
    "            x::INT AS x,\n",
    "            y::INT AS y,\n",
    "            flow,\n",
    "            {\", \".join([f\"COALESCE({c}, 0) AS {c}\" for c in poi_cols])},\n",
    "            t AS time_of_day,\n",
    "            d % 7 AS dow,\n",
    "            (d * 48 + t) AS time_index\n",
    "        FROM flow_poi\n",
    "    ),\n",
    "    feat AS (\n",
    "        SELECT\n",
    "            *,\n",
    "            sin(2*PI()*time_of_day/48.0) AS tod_sin,\n",
    "            cos(2*PI()*time_of_day/48.0) AS tod_cos,\n",
    "            sin(2*PI()*dow/7.0)          AS dow_sin,\n",
    "            cos(2*PI()*dow/7.0)          AS dow_cos,\n",
    "            LEAD(flow) OVER (\n",
    "                PARTITION BY x, y\n",
    "                ORDER BY d, t\n",
    "            ) AS flow_next\n",
    "        FROM base\n",
    "    )\n",
    "    SELECT\n",
    "        x,\n",
    "        y,\n",
    "        {\", \".join(feature_cols)},\n",
    "        flow_next,\n",
    "        time_index\n",
    "    FROM feat\n",
    "    WHERE flow_next IS NOT NULL;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QXH14XSDBlv",
    "outputId": "5958c191-e37e-4d84-b8c5-b6e7d007e3f8"
   },
   "outputs": [],
   "source": [
    "print(con.execute(\"SELECT COUNT(*) FROM flow_feat;\").fetchall())\n",
    "print(con.execute(\"PRAGMA table_info('flow_feat');\").fetchall()[:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/005.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train–test split and feature normalization\n",
    "\n",
    "To prepare the data for modeling, we perform a temporal split on the feature\n",
    "table `flow_feat`. Because mobility patterns evolve over time, the model should\n",
    "be evaluated on future data rather than on randomly shuffled samples. We therefore\n",
    "split the dataset by the global `time_index`:\n",
    "\n",
    "1. We compute the 80th percentile of `time_index` across all rows.\n",
    "2. Rows with `time_index` ≤ threshold form the training set (`flow_feat_train`).\n",
    "3. Rows with `time_index` > threshold form the test set (`flow_feat_test`).\n",
    "\n",
    "This ensures that the model is trained only on past observations and evaluated\n",
    "on genuinely later time periods.\n",
    "\n",
    "After splitting, we compute feature-wise means and standard deviations **only on\n",
    "the training set**. These statistics are collected for each model input feature in\n",
    "`feature_cols`. They are later used to apply z-score normalization to both training and test sequences. Computing normalization parameters solely\n",
    "from the training set avoids information leakage from the future into the model.\n",
    "\n",
    "The resulting arrays `mean` and `std` store the normalization parameters in a\n",
    "consistent order that matches the feature layout used by NumPy and PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "c3237904e88c495fb6b7a5cbc0eb8250",
      "c65e99c1a08442bbac7f55982bfa2fce",
      "c24fc8161f9d4cce9d68742e88fb3557",
      "3167a68725e540f0af32f451355cfc6c",
      "20cd043dda8e4005a3dca3dc9ba9f124",
      "8a6a0dc81bfa434a881836b2573748c7",
      "1e8904910b4c434092dbe95e446c6f61",
      "c937d5ff2bbb45a797463a32bf209f93",
      "16a0aa33eb94474da5adb27911544b02",
      "db8c32a1000847a79632f36831d88430",
      "edc51a08a0b74ae387c84b7822eb5ea2",
      "08add841df264cdab83e0e1c339694ae"
     ]
    },
    "id": "LsrqlpuD8WMc",
    "outputId": "c10773a1-bc64-45a6-e28f-9755e5a4059f"
   },
   "outputs": [],
   "source": [
    "# 80% threshold\n",
    "import numpy as np\n",
    "\n",
    "threshold = con.execute(\"\"\"\n",
    "    SELECT quantile(time_index, 0.8) FROM flow_feat;\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE flow_feat_train AS\n",
    "    SELECT * FROM flow_feat\n",
    "    WHERE time_index <= ?;\n",
    "\"\"\", [threshold])\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE flow_feat_test AS\n",
    "    SELECT * FROM flow_feat\n",
    "    WHERE time_index > ?;\n",
    "\"\"\", [threshold])\n",
    "\n",
    "# mean / std\n",
    "mean_row = con.execute(f\"\"\"\n",
    "    SELECT {\", \".join([f\"avg({c}) AS {c}\" for c in feature_cols])}\n",
    "    FROM flow_feat_train;\n",
    "\"\"\").fetchnumpy()\n",
    "\n",
    "std_row = con.execute(f\"\"\"\n",
    "    SELECT {\", \".join([f\"stddev_samp({c}) AS {c}\" for c in feature_cols])}\n",
    "    FROM flow_feat_train;\n",
    "\"\"\").fetchnumpy()\n",
    "\n",
    "mean = np.array([mean_row[c][0] for c in feature_cols], dtype=\"float32\")\n",
    "std  = np.array([std_row[c][0]  for c in feature_cols], dtype=\"float32\") + 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1L2wF51qKgZ"
   },
   "source": [
    "### 3. Sequence construction\n",
    "\n",
    "To train temporal models, we convert the flat table `flow_feat` into short,\n",
    "fixed-length sequences for each grid cell. These sequences represent a brief\n",
    "history of recent observations, followed by the flow value that occurs\n",
    "immediately afterward.\n",
    "\n",
    "The construction process works cell by cell. For each table\n",
    "(`flow_feat_train` or `flow_feat_test`), we first identify every grid cell\n",
    "that contains at least `SEQ_LEN` time steps. For each eligible cell, we\n",
    "retrieve all of its records ordered by the global `time_index` so that the\n",
    "time series is consistent and gap-free.\n",
    "\n",
    "From this ordered sequence, we slide a window of length `SEQ_LEN` over the\n",
    "cell’s history. The window moves forward by a fixed stride (e.g., 4 time\n",
    "steps) to avoid generating overly similar samples. Each window contains:\n",
    "\n",
    "- a sequence of `SEQ_LEN` standardized feature vectors, representing the\n",
    "  cell’s recent historical states;\n",
    "- a target value equal to the `flow_next` associated with the **final**\n",
    "  time step inside that window.\n",
    "\n",
    "In other words, every training example describes “the previous eight half-hours”\n",
    "and pairs it with “the flow in the next half-hour.” The generator bundles these\n",
    "examples into mini-batches:\n",
    "\n",
    "- `X_batch` has shape `[batch_size, SEQ_LEN, feature_dim]`, containing the\n",
    "  input histories;\n",
    "- `y_batch` has shape `[batch_size]`, containing the corresponding next-step\n",
    "  flow targets.\n",
    "\n",
    "These mini-batches form the direct input to both the linear model and the LSTM\n",
    "model during training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwgYxNk38jC5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "SEQ_LEN   = 8\n",
    "BATCH_SIZE = 1024\n",
    "STRIDE    = 4\n",
    "\n",
    "def seq_batch_generator(table_name, batch_size=BATCH_SIZE, seq_len=SEQ_LEN, max_cells=None):\n",
    "    \"\"\"\n",
    "    Generate sequence batches from flow_feat_train / flow_feat_test.\n",
    "\n",
    "    X_batch: [batch, seq_len, feature_dim]\n",
    "    y_batch: [batch]\n",
    "    \"\"\"\n",
    "    cells = con.execute(f\"\"\"\n",
    "        SELECT x, y\n",
    "        FROM {table_name}\n",
    "        GROUP BY x, y\n",
    "        HAVING COUNT(*) >= {seq_len}\n",
    "    \"\"\").fetchall()\n",
    "\n",
    "    if max_cells is not None:\n",
    "        cells = cells[:max_cells]\n",
    "\n",
    "    print(f\"{table_name}: {len(cells)} cells with >= {seq_len} records\")\n",
    "\n",
    "    for (x_val, y_val) in cells:\n",
    "        res = con.execute(f\"\"\"\n",
    "            SELECT time_index, {\", \".join(feature_cols)}, flow_next\n",
    "            FROM {table_name}\n",
    "            WHERE x = ? AND y = ?\n",
    "            ORDER BY time_index\n",
    "        \"\"\", [x_val, y_val]).fetchnumpy()\n",
    "\n",
    "        n = len(res[\"flow_next\"])\n",
    "        if n < seq_len:\n",
    "            continue\n",
    "\n",
    "        feats = np.column_stack([res[c] for c in feature_cols]).astype(\"float32\")\n",
    "        feats = (feats - mean) / std\n",
    "\n",
    "        y_vec = res[\"flow_next\"].astype(\"float32\")\n",
    "\n",
    "        X_buf, y_buf = [], []\n",
    "\n",
    "        for i in range(0, n - seq_len + 1, STRIDE):\n",
    "            X_seq = feats[i:i+seq_len]           # [seq_len, F]\n",
    "            y_target = y_vec[i + seq_len - 1]    # scalar\n",
    "\n",
    "            X_buf.append(X_seq)\n",
    "            y_buf.append(y_target)\n",
    "\n",
    "            if len(X_buf) == batch_size:\n",
    "                yield np.stack(X_buf), np.array(y_buf)\n",
    "                X_buf, y_buf = [], []\n",
    "\n",
    "        if len(X_buf) > 0:\n",
    "            yield np.stack(X_buf), np.array(y_buf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 LSTM model\n",
    "\n",
    "The first predictive model we use is an LSTM-based sequence model designed to\n",
    "capture temporal structure in mobility flows. Each input sample is a\n",
    "fixed-length sequence containing `SEQ_LEN` consecutive half-hour records for a\n",
    "single grid cell. Each record has the full feature vector consisting of the\n",
    "flow value, POI-based attributes, and the time-encoding variables.\n",
    "\n",
    "The LSTM processes these sequences one time step at a time. As it moves through\n",
    "the eight input steps, it maintains a hidden state that summarizes the\n",
    "information accumulated so far. After the final time step, the hidden state\n",
    "represents the model’s understanding of the recent history of the cell.\n",
    "\n",
    "To make a prediction, we take this final hidden state and feed it into a\n",
    "fully connected layer that outputs a single value: the predicted next-step\n",
    "flow. This structure allows the model to learn temporal dependencies,\n",
    "non-linear feature interactions, and recurring movement patterns across days.\n",
    "\n",
    "The LSTM used here has:\n",
    "- batch-first input format,\n",
    "- a hidden size of 64,\n",
    "- two stacked recurrent layers,\n",
    "- and a final linear layer that maps the hidden representation into a scalar\n",
    "  prediction.\n",
    "\n",
    "The model is trained end-to-end with the Adam optimizer and mean squared error\n",
    "as the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "\n",
    "class FlowLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F]\n",
    "        out, _ = self.lstm(x)        \n",
    "        last_hidden = out[:, -1, :]   \n",
    "        y_pred = self.fc(last_hidden)  \n",
    "        return y_pred.squeeze(-1)     \n",
    "\n",
    "\n",
    "class LinearSeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.fc = nn.Linear(input_dim * seq_len, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F]\n",
    "        B, L, F = x.shape\n",
    "        x_flat = x.reshape(B, L * F)  \n",
    "        y_pred = self.fc(x_flat)       \n",
    "        return y_pred.squeeze(-1)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Linear sequence baseline\n",
    "\n",
    "To provide a simple point of comparison, we also include a linear baseline\n",
    "model. Instead of using a recurrent structure, this model treats the entire\n",
    "input sequence as a single flat vector. All `SEQ_LEN` feature rows are\n",
    "concatenated into one long input, and the model applies a single fully\n",
    "connected layer to map this vector directly to a predicted next-step flow.\n",
    "\n",
    "This baseline has no notion of temporal order or temporal dependency. It can\n",
    "only learn a weighted combination of the raw features but cannot model how\n",
    "patterns evolve over time. As a result, it serves as a useful reference for\n",
    "evaluating whether the LSTM’s recurrent structure truly provides additional\n",
    "predictive power.\n",
    "\n",
    "Despite its simplicity, the linear model is fast to train and helps quantify\n",
    "the value of incorporating temporal dynamics into the prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0sP9Zc_-cy5",
    "outputId": "094f038d-6f2d-4c24-ecc4-47ee82d7df1c"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "hidden_dim = 64\n",
    "num_layers = 2\n",
    "\n",
    "class FlowLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, F]\n",
    "        out, _ = self.lstm(x)          # out: [B, L, H]\n",
    "        last_hidden = out[:, -1, :]    # [B, H] -> last time step\n",
    "        y_pred = self.fc(last_hidden)  # [B, 1]\n",
    "        return y_pred.squeeze(-1)      # [B]\n",
    "\n",
    "model = FlowLSTM(input_dim, hidden_dim, num_layers).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHmEVHlH-k3n"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_mse_seq(table_name: str) -> float:\n",
    "    model.eval()\n",
    "    sq_sum = 0.0\n",
    "    n = 0\n",
    "    for X_batch, y_batch in seq_batch_generator(table_name, batch_size=BATCH_SIZE, seq_len=SEQ_LEN):\n",
    "        xb = torch.from_numpy(X_batch).to(device)  # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)  # [B]\n",
    "        pred = model(xb)                           # [B]\n",
    "        sq_sum += ((pred - yb) ** 2).sum().item()\n",
    "        n += len(yb)\n",
    "    return sq_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJYSw8Kop4LP"
   },
   "source": [
    "### 5. Training\n",
    "\n",
    "Both the LSTM model and the linear baseline model are trained using the\n",
    "mini-batches produced by the sequence generator. Each batch contains a set of\n",
    "short historical sequences for different grid cells, paired with the flow value\n",
    "that occurs immediately afterward.\n",
    "\n",
    "During training, the model loops over all batches from `flow_feat_train`.\n",
    "For each batch:\n",
    "\n",
    "1. The input sequences are passed through the model to obtain predictions of the\n",
    "   next-step flow.\n",
    "2. These predictions are compared with the true targets using mean squared error\n",
    "   as the loss function.\n",
    "3. The optimizer (Adam) updates the model parameters to reduce this loss.\n",
    "\n",
    "This process is repeated for several epochs. After each epoch, the model is\n",
    "evaluated on `flow_feat_test` using the same sequence construction procedure.\n",
    "The test-set mean squared error provides a forward-looking measure of\n",
    "performance, since the test rows correspond to later time periods that were not\n",
    "used during training.\n",
    "\n",
    "For the LSTM model, training checkpoints are saved after each epoch, including\n",
    "the model parameters, optimizer state, and the current training and test\n",
    "metrics. A final set of model weights is also saved separately for inference\n",
    "and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKdheDwO-k0N",
    "outputId": "11dfb98f-78ad-49c3-a892-40ce212405b6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LinearSeqModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, seq_len: int):\n",
    "        \"\"\"\n",
    "        input_dim: len(feature_cols)\n",
    "        seq_len  : SEQ_LEN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.fc = nn.Linear(input_dim * seq_len, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, L*F]\n",
    "        \"\"\"\n",
    "        y_pred = self.fc(x)          # [B, 1]\n",
    "        return y_pred.squeeze(-1)    # [B]\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "input_dim = len(feature_cols)\n",
    "\n",
    "lin_model = LinearSeqModel(input_dim=input_dim, seq_len=SEQ_LEN).to(device)\n",
    "lin_loss_fn = nn.MSELoss()\n",
    "lin_optimizer = torch.optim.Adam(lin_model.parameters(), lr=1e-3)\n",
    "\n",
    "print(lin_model)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mse_linear(model, table_name: str, max_cells=None) -> float:\n",
    "    model.eval()\n",
    "    sq_sum = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        table_name,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=max_cells\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)    # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)    # [B]\n",
    "\n",
    "        xb = xb.reshape(xb.shape[0], -1)             # [B, L*F]\n",
    "\n",
    "        pred = model(xb)                             # [B]\n",
    "        sq_sum += ((pred - yb) ** 2).sum().item()\n",
    "        n += len(yb)\n",
    "\n",
    "    return sq_sum / n\n",
    "\n",
    "\n",
    "EPOCHS_LIN = 8\n",
    "\n",
    "for epoch in range(1, EPOCHS_LIN + 1):\n",
    "    lin_model.train()\n",
    "    train_sq_sum = 0.0\n",
    "    train_n = 0\n",
    "    batch_idx = 0\n",
    "\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        \"flow_feat_train\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=None\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)    # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)    # [B]\n",
    "\n",
    "        # flatten [B, L*F]\n",
    "        xb = xb.reshape(xb.shape[0], -1)\n",
    "\n",
    "        lin_optimizer.zero_grad()\n",
    "        pred = lin_model(xb)                         # [B]\n",
    "        loss = lin_loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        lin_optimizer.step()\n",
    "\n",
    "        train_sq_sum += ((pred.detach() - yb) ** 2).sum().item()\n",
    "        train_n += len(yb)\n",
    "\n",
    "        batch_idx += 1\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"[Linear] Epoch {epoch:02d} | Processed {batch_idx} batches\")\n",
    "\n",
    "    #  train / test MSE\n",
    "    train_mse = train_sq_sum / train_n\n",
    "    test_mse = evaluate_mse_linear(lin_model, \"flow_feat_test\", max_cells=None)\n",
    "\n",
    "    print(f\"[Linear] Epoch {epoch:02d} | Train MSE {train_mse:.4f} | Test MSE {test_mse:.4f}\")\n",
    "\n",
    "torch.save(\n",
    "    lin_model.state_dict(),\n",
    "    \"/content/drive/MyDrive/MOBILITY/flow_linear_seq_epoch8.pth\"\n",
    ")\n",
    "print(\"Saved linear baseline model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/006.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4MAIVJP-kxt",
    "outputId": "fdb640ff-5553-4940-9320-af3d1a706229"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# checkpoint\n",
    "ckpt_dir = \"/content/drive/MyDrive/MOBILITY/checkpoints_lstm\"\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# ----- training loop ----- checkpoint\n",
    "EPOCHS = 8\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_mse_seq(table_name: str, max_cells=None) -> float:\n",
    "    model.eval()\n",
    "    sq_sum = 0.0\n",
    "    n = 0\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        table_name,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=max_cells\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)  # [B, L, F]\n",
    "        yb = torch.from_numpy(y_batch).to(device)  # [B]\n",
    "        pred = model(xb)                           # [B]\n",
    "        sq_sum += ((pred - yb) ** 2).sum().item()\n",
    "        n += len(yb)\n",
    "    return sq_sum / n\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_sq_sum = 0.0\n",
    "    train_n = 0\n",
    "\n",
    "    batch_idx = 0\n",
    "\n",
    "    # Here you can set max_cells for debugging; set to None for full data\n",
    "    for X_batch, y_batch in seq_batch_generator(\n",
    "        \"flow_feat_train\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seq_len=SEQ_LEN,\n",
    "        max_cells=None\n",
    "    ):\n",
    "        xb = torch.from_numpy(X_batch).to(device)\n",
    "        yb = torch.from_numpy(y_batch).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_sq_sum += ((pred.detach() - yb) ** 2).sum().item()\n",
    "        train_n += len(yb)\n",
    "\n",
    "        batch_idx += 1\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch:02d} | Processed {batch_idx} batches so far\")\n",
    "\n",
    "    train_mse = train_sq_sum / train_n\n",
    "    test_mse = evaluate_mse_seq(\"flow_feat_test\", max_cells=None)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train MSE {train_mse:.4f} | Test MSE {test_mse:.4f}\")\n",
    "\n",
    "    ckpt_path = os.path.join(ckpt_dir, f\"flow_lstm_epoch{epoch:02d}.pth\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"train_mse\": train_mse,\n",
    "            \"test_mse\": test_mse,\n",
    "        },\n",
    "        ckpt_path,\n",
    "    )\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "\n",
    "final_path = \"/content/drive/MyDrive/MOBILITY/flow_lstm_final.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(f\"Saved final model to {final_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/007.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Spatial visualization\n",
    "\n",
    "To understand where and when the models perform well, we visualize predictions\n",
    "across the spatial grid. The idea is to fix a specific day and one or more\n",
    "time-of-day slots, reconstruct the historical sequences for each grid cell at\n",
    "those times, run the trained model, and compare its predictions with the true\n",
    "flows.\n",
    "\n",
    "The visualization works in two modes:\n",
    "\n",
    "1. **Single time slice**\n",
    "   - Choose a day and an eight-step window within that day.\n",
    "   - For the final time step of the window, identify all grid cells that have a\n",
    "     valid next-step flow.\n",
    "   - For each of these cells, retrieve the preceding `SEQ_LEN` records to form a\n",
    "     complete history.\n",
    "   - After running the model, create a spatial plot showing:\n",
    "     - the true next-step flow,\n",
    "     - the model’s predicted flow,\n",
    "     - and the absolute error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-5ESx1W72Lf",
    "outputId": "22827492-36ff-4a93-ee67-21e047555b19"
   },
   "outputs": [],
   "source": [
    "d0 = 64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_t = 16\n",
    "window_len = 8\n",
    "end_t = start_t + window_len - 1\n",
    "\n",
    "window_df = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        x,\n",
    "        y,\n",
    "        (time_index % 48) AS t,\n",
    "        flow\n",
    "    FROM flow_feat_test\n",
    "    WHERE (time_index / 48)::INT = ?\n",
    "      AND (time_index % 48) BETWEEN ? AND ?\n",
    "\"\"\", [d0, start_t, end_t]).fetchdf()\n",
    "\n",
    "print(window_df.head())\n",
    "print(\"records have =\", len(window_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXiMttw7MC91",
    "outputId": "0c33ada2-4767-42f9-b615-7cbb60f19c07"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "t_plot = end_t\n",
    "\n",
    "snap_true = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "        x,\n",
    "        y,\n",
    "        flow_next AS target,\n",
    "        time_index\n",
    "    FROM flow_feat_test\n",
    "    WHERE (time_index / 48)::INT = ?\n",
    "      AND (time_index % 48) = ?;\n",
    "\"\"\", [d0, t_plot]).fetchdf()\n",
    "\n",
    "print(\"cells at this time step:\", len(snap_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/004.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0mmrNbhMLsV",
    "outputId": "8a220176-9fe2-434a-d196-35e427b6973d"
   },
   "outputs": [],
   "source": [
    "X_list, target_list, x_list, y_list = [], [], [], []\n",
    "\n",
    "for idx, row in snap_true.iterrows():\n",
    "    x0 = int(row[\"x\"])\n",
    "    y0 = int(row[\"y\"])\n",
    "    T  = int(row[\"time_index\"])\n",
    "    y_true = float(row[\"target\"])\n",
    "\n",
    "    seq_df = con.execute(f\"\"\"\n",
    "        SELECT time_index, {\", \".join(feature_cols)}\n",
    "        FROM (\n",
    "            SELECT time_index, {\", \".join(feature_cols)}\n",
    "            FROM flow_feat_test\n",
    "            WHERE x = ? AND y = ?\n",
    "              AND (time_index / 48)::INT = ?\n",
    "              AND time_index <= ?\n",
    "            ORDER BY time_index DESC\n",
    "            LIMIT ?\n",
    "        )\n",
    "        ORDER BY time_index;\n",
    "    \"\"\", [x0, y0, d0, T, SEQ_LEN]).fetchdf()\n",
    "\n",
    "    if len(seq_df) < SEQ_LEN:\n",
    "        continue\n",
    "\n",
    "    feats = seq_df[feature_cols].to_numpy(dtype=\"float32\")\n",
    "    feats_norm = (feats - mean) / std\n",
    "\n",
    "    X_list.append(feats_norm)\n",
    "    target_list.append(y_true)\n",
    "    x_list.append(x0)\n",
    "    y_list.append(y0)\n",
    "\n",
    "print(\"usable cells with full 8-step history:\", len(X_list))\n",
    "\n",
    "X = np.stack(X_list).astype(\"float32\")       # [N, L, F]\n",
    "y_true_arr = np.array(target_list, dtype=\"float32\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xb = torch.from_numpy(X).to(device)     # [N, L, F]\n",
    "    pred_arr = model(xb).cpu().numpy()      # [N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kqSLaZjOgN4"
   },
   "outputs": [],
   "source": [
    "snap = pd.DataFrame({\n",
    "    \"x\": x_list,\n",
    "    \"y\": y_list,\n",
    "    \"flow_true\": y_true_arr,     # true next-step flow\n",
    "    \"flow_pred\": pred_arr,       # LSTM predicted next-step flow\n",
    "})\n",
    "snap[\"err_abs\"] = np.abs(snap[\"flow_pred\"] - snap[\"flow_true\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "uBLQ7zR2OiAx",
    "outputId": "3b76a674-d5cf-4587-ab7d-c75047eb81f3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vmin = np.percentile(snap[\"flow_true\"], 5)\n",
    "vmax = np.percentile(snap[\"flow_true\"], 95)\n",
    "\n",
    "err_max = np.percentile(snap[\"err_abs\"], 95)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax = axes[0]\n",
    "sc0 = ax.scatter(\n",
    "    snap[\"x\"], snap[\"y\"],\n",
    "    c=snap[\"flow_true\"],\n",
    "    s=10,\n",
    "    cmap=\"plasma\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "ax.set_title(\"True next-step flow\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(False)\n",
    "plt.colorbar(sc0, ax=ax, label=\"flow_true\")\n",
    "\n",
    "ax = axes[1]\n",
    "sc1 = ax.scatter(\n",
    "    snap[\"x\"], snap[\"y\"],\n",
    "    c=snap[\"flow_pred\"],\n",
    "    s=10,\n",
    "    cmap=\"plasma\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax\n",
    ")\n",
    "ax.set_title(\"LSTM predicted next-step flow\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(False)\n",
    "plt.colorbar(sc1, ax=ax, label=\"flow_pred\")\n",
    "\n",
    "ax = axes[2]\n",
    "sc2 = ax.scatter(\n",
    "    snap[\"x\"], snap[\"y\"],\n",
    "    c=snap[\"err_abs\"],\n",
    "    s=10,\n",
    "    cmap=\"magma\",\n",
    "    vmin=0,\n",
    "    vmax=err_max\n",
    ")\n",
    "ax.set_title(\"|pred − true|\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.grid(False)\n",
    "plt.colorbar(sc2, ax=ax, label=\"abs error\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "\n",
    "minutes = t_plot * 30\n",
    "hh = minutes // 60\n",
    "mm = minutes % 60\n",
    "plt.suptitle(f\"Day {d0}, t={t_plot} (~{hh:02d}:{mm:02d}) – next-step flow\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Multiple time slices**\n",
    "   - Select several time-of-day indices on the same day.\n",
    "   - Repeat the above process for each time, stacking the resulting maps\n",
    "     side-by-side.\n",
    "   - The first row displays true flows, the second row shows predictions, and\n",
    "     the third row shows absolute errors.\n",
    "   - Shared color scales allow visual comparison across time.\n",
    "\n",
    "These visualizations reveal spatial heterogeneity in both mobility patterns and\n",
    "model performance. They help identify when the model struggles, which regions\n",
    "tend to be more predictable, and how flow dynamics evolve over the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjhGCMKjOxjP",
    "outputId": "5af24f16-c7ae-41ba-d277-6099a8e7c2c9"
   },
   "outputs": [],
   "source": [
    "d0 = 64\n",
    "\n",
    "t_list = [8, 12, 16, 20, 24, 28]\n",
    "\n",
    "snap_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for t_plot in t_list:\n",
    "    snap_true = con.execute(\"\"\"\n",
    "        SELECT\n",
    "            x,\n",
    "            y,\n",
    "            flow_next AS target,\n",
    "            time_index\n",
    "        FROM flow_feat_test\n",
    "        WHERE (time_index / 48)::INT = ?\n",
    "          AND (time_index % 48) = ?;\n",
    "    \"\"\", [d0, t_plot]).fetchdf()\n",
    "\n",
    "    X_list, target_list, x_list, y_list = [], [], [], []\n",
    "\n",
    "    for idx, row in snap_true.iterrows():\n",
    "        x0 = int(row[\"x\"])\n",
    "        y0 = int(row[\"y\"])\n",
    "        T  = int(row[\"time_index\"])\n",
    "        y_true = float(row[\"target\"])\n",
    "\n",
    "        seq_df = con.execute(f\"\"\"\n",
    "            SELECT time_index, {\", \".join(feature_cols)}\n",
    "            FROM (\n",
    "                SELECT time_index, {\", \".join(feature_cols)}\n",
    "                FROM flow_feat_test\n",
    "                WHERE x = ? AND y = ?\n",
    "                  AND (time_index / 48)::INT = ?\n",
    "                  AND time_index <= ?\n",
    "                ORDER BY time_index DESC\n",
    "                LIMIT ?\n",
    "            )\n",
    "            ORDER BY time_index;\n",
    "        \"\"\", [x0, y0, d0, T, SEQ_LEN]).fetchdf()\n",
    "\n",
    "        if len(seq_df) < SEQ_LEN:\n",
    "            continue\n",
    "\n",
    "        feats = seq_df[feature_cols].to_numpy(dtype=\"float32\")\n",
    "        feats_norm = (feats - mean) / std\n",
    "\n",
    "        X_list.append(feats_norm)\n",
    "        target_list.append(y_true)\n",
    "        x_list.append(x0)\n",
    "        y_list.append(y0)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        print(f\"t={t_plot} no enough\")\n",
    "        continue\n",
    "\n",
    "    X = np.stack(X_list).astype(\"float32\")\n",
    "    y_true_arr = np.array(target_list, dtype=\"float32\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        xb = torch.from_numpy(X).to(device)\n",
    "        y_pred_arr = model(xb).cpu().numpy()\n",
    "\n",
    "    snap = pd.DataFrame({\n",
    "        \"x\": x_list,\n",
    "        \"y\": y_list,\n",
    "        \"flow_true\": y_true_arr,\n",
    "        \"flow_pred\": y_pred_arr,\n",
    "    })\n",
    "    snap[\"err_abs\"] = np.abs(snap[\"flow_pred\"] - snap[\"flow_true\"])\n",
    "    snap[\"t_plot\"] = t_plot\n",
    "\n",
    "    snap_list.append(snap)\n",
    "\n",
    "print(\"usable time points\", len(snap_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "id": "lMUR-w1_eKmJ",
    "outputId": "dae2130c-2fad-4a07-d38e-e69819bfedbd"
   },
   "outputs": [],
   "source": [
    "all_snap = pd.concat(snap_list, ignore_index=True)\n",
    "vmin = np.percentile(all_snap[\"flow_true\"], 5)\n",
    "vmax = np.percentile(all_snap[\"flow_true\"], 95)\n",
    "err_max = np.percentile(all_snap[\"err_abs\"], 95)\n",
    "\n",
    "n_times = len(snap_list)\n",
    "snap_list_sorted = sorted(snap_list, key=lambda s: s[\"t_plot\"].iloc[0])\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    3, n_times,\n",
    "    figsize=(3.0 * n_times, 8),\n",
    "    sharex=True, sharey=True\n",
    ")\n",
    "\n",
    "sc_true = None\n",
    "sc_err = None\n",
    "\n",
    "for j, snap in enumerate(snap_list_sorted):\n",
    "    t_plot = snap[\"t_plot\"].iloc[0]\n",
    "\n",
    "    ax = axes[0, j]\n",
    "    sc_true = ax.scatter(\n",
    "        snap[\"x\"], snap[\"y\"],\n",
    "        c=snap[\"flow_true\"],\n",
    "        s=5,\n",
    "        cmap=\"plasma\",\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax.set_title(f\"t={t_plot} True\", fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    ax = axes[1, j]\n",
    "    ax.scatter(\n",
    "        snap[\"x\"], snap[\"y\"],\n",
    "        c=snap[\"flow_pred\"],\n",
    "        s=5,\n",
    "        cmap=\"plasma\",\n",
    "        vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax.set_title(f\"t={t_plot} Pred\", fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    ax = axes[2, j]\n",
    "    sc_err = ax.scatter(\n",
    "        snap[\"x\"], snap[\"y\"],\n",
    "        c=snap[\"err_abs\"],\n",
    "        s=5,\n",
    "        cmap=\"magma\",\n",
    "        vmin=0, vmax=err_max\n",
    "    )\n",
    "    ax.set_title(f\"t={t_plot} |Pred−True|\", fontsize=10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.grid(False)\n",
    "\n",
    "for j in range(n_times):\n",
    "    axes[2, j].set_xlabel(\"x\")\n",
    "for i in range(3):\n",
    "    axes[i, 0].set_ylabel(\"y\")\n",
    "\n",
    "plt.subplots_adjust(\n",
    "    left=0.06, right=0.9,\n",
    "    top=0.9, bottom=0.08,\n",
    "    wspace=0.05, hspace=0.12\n",
    ")\n",
    "\n",
    "cbar1 = fig.colorbar(\n",
    "    sc_true,\n",
    "    ax=axes[0:2, -1],\n",
    "    fraction=0.046,\n",
    "    pad=0.02\n",
    ")\n",
    "cbar1.set_label(\"flow\")\n",
    "\n",
    "cbar2 = fig.colorbar(\n",
    "    sc_err,\n",
    "    ax=axes[2, -1],\n",
    "    fraction=0.046,\n",
    "    pad=0.04\n",
    ")\n",
    "cbar2.set_label(\"abs error\")\n",
    "\n",
    "plt.suptitle(f\"Day {d0} – 6 time steps: True / Pred / Error\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image/003.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The results demonstrate that temporal modeling is essential for predicting\n",
    "grid-based mobility flows. The linear baseline, which treats the input sequence\n",
    "as a single flattened vector, fails to capture temporal structure: its test MSE\n",
    "is more than two orders of magnitude worse than that of the LSTM. In contrast,\n",
    "the LSTM achieves stable performance (train MSE ≈ 3.79, test MSE ≈ 4.15),\n",
    "indicating that it successfully learns short-term temporal dependencies in the\n",
    "flow dynamics.\n",
    "\n",
    "Spatial visualizations further confirm this pattern. Across six representative\n",
    "time steps on Day 64, the LSTM reproduces the broad spatial structure of flow,\n",
    "accurately matching both low-flow regions and the major concentration zones.\n",
    "Prediction errors are primarily concentrated in high-intensity areas—locations\n",
    "where flow is both larger in magnitude and more volatile. This suggests that\n",
    "the LSTM captures routine, low-variance mobility well, while sudden spikes or\n",
    "irregular flow patterns remain harder to model.\n",
    "\n",
    "Overall, the experiment shows that:\n",
    "1. Temporal information is crucial for mobility forecasting.\n",
    "2. Even a relatively small LSTM (hidden size 64, two layers) is sufficient to\n",
    "   outperform non-temporal baselines by a wide margin.\n",
    "3. The remaining errors are spatially structured, pointing toward opportunities\n",
    "   for future extensions such as attention mechanisms or spatial graph models.\n",
    "\n",
    "The LSTM therefore provides a strong foundation for next-step mobility\n",
    "prediction, and the spatial evaluation highlights where more advanced models\n",
    "may yield additional gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08add841df264cdab83e0e1c339694ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "16a0aa33eb94474da5adb27911544b02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "1e8904910b4c434092dbe95e446c6f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c937d5ff2bbb45a797463a32bf209f93",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16a0aa33eb94474da5adb27911544b02",
      "value": 100
     }
    },
    "20cd043dda8e4005a3dca3dc9ba9f124": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "3167a68725e540f0af32f451355cfc6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20cd043dda8e4005a3dca3dc9ba9f124",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a6a0dc81bfa434a881836b2573748c7",
      "value": 100
     }
    },
    "66a54dd5da574abe8fdbf9e1a411f04d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc8e16af08dd497686bb86121677c2aa",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a775d29f4fd94d979256b7422a7b9a07",
      "value": 100
     }
    },
    "8a6a0dc81bfa434a881836b2573748c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "a775d29f4fd94d979256b7422a7b9a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "c24fc8161f9d4cce9d68742e88fb3557": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "c3237904e88c495fb6b7a5cbc0eb8250": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c65e99c1a08442bbac7f55982bfa2fce",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c24fc8161f9d4cce9d68742e88fb3557",
      "value": 100
     }
    },
    "c65e99c1a08442bbac7f55982bfa2fce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "c937d5ff2bbb45a797463a32bf209f93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "db8c32a1000847a79632f36831d88430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edc51a08a0b74ae387c84b7822eb5ea2",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08add841df264cdab83e0e1c339694ae",
      "value": 100
     }
    },
    "dc8e16af08dd497686bb86121677c2aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "edc51a08a0b74ae387c84b7822eb5ea2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
